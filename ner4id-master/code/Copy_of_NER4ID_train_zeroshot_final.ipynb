{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otNnz5AWLq3W"
      },
      "source": [
        "# NER4ID at SemEval-2022 Task 2: Named Entity Recognition for Idiomaticity Detection\n",
        "----------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/babelscape/ner4id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu0EDLAOM1Wj",
        "outputId": "ad300587-bf8e-4f11-985b-880de63e6781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ner4id'...\n",
            "remote: Enumerating objects: 56, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 56 (delta 20), reused 41 (delta 10), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (56/56), 1.58 MiB | 6.19 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhHoi-8LLq3Y"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzZNVo0Bjn0t",
        "outputId": "e62e07d2-c460-4a0f-dca1-9f47518efdf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers\n",
        "! pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0q_SRDCMmrNk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.optim as optim\n",
        " \n",
        "from pprint import pprint\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from transformers import BertTokenizer, BertModel, BertConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-ybIBmlLq3d"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"../\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Q5rzN_LXmy3B",
        "outputId": "27535984-95ef-4023-fe3d-13e802ad913e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.0+cu118\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "print(torch.__version__)\n",
        "torch.cuda.current_device()\n",
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_n--BTtLq3e"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZjxrflHLq3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e06b6f63-a720-4fbf-b5e4-f6b3bd44d32e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Do you want to train a model from scratch or do you want to evaluate a pretrained model? Possible answers: ['train', 'eval']\n",
            "> train\n",
            "\n",
            "In which setting do you want to train/evaluate your model? Possible answers: ['zero-shot', 'one-shot']\n",
            ">zero-shot\n"
          ]
        }
      ],
      "source": [
        "mode = input(\"Do you want to train a model from scratch or do you want to evaluate a pretrained model? Possible answers: ['train', 'eval']\\n> \")\n",
        "assert mode in ['train', 'eval']\n",
        "\n",
        "setting = input(\"\\nIn which setting do you want to train/evaluate your model? Possible answers: ['zero-shot', 'one-shot']\\n>\")\n",
        "assert setting in ['zero-shot', 'one-shot']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CBHdcuhnXBn"
      },
      "outputs": [],
      "source": [
        "train_file_zero_shot = \"/content/ner4id/data/train_zero_shot.csv\" \n",
        "train_file_one_shot = \"/content/ner4id/data/train_one_shot.csv\"\n",
        "\n",
        "dev_file = \"/content/ner4id/data/dev.csv\"\n",
        "dev_file_gold = \"/content/ner4id/data/dev_gold.csv\"\n",
        "test_file = \"/content/ner4id/data/test.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "RLFxTNwGNo4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_sm"
      ],
      "metadata": {
        "id": "k5meTmcYOLI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d6b730-1631-464c-a332-3338bd571802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-09 16:25:51.603655: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pt-core-news-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.5.0/pt_core_news_sm-3.5.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from pt-core-news-sm==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2.1.2)\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhxWcT1gGnuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80da7172-358d-4ac4-c717-30956e17e851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import en_core_web_sm\n",
        "import pt_core_news_sm\n",
        "from spacy.cli.download import download as spacy_download\n",
        "\n",
        "spacy_download(\"en_core_web_sm\")\n",
        "spacy_tagger_en = spacy.load(\"en_core_web_sm\", exclude=[\"ner\", \"parser\"])\n",
        "\n",
        "spacy_download(\"pt_core_news_sm\")\n",
        "spacy_tagger_pt = spacy.load(\"pt_core_news_sm\", exclude=[\"ner\", \"parser\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ4tYxBaoUhl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6993612f-2d61-49d6-9e95-f30284b1946a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4492it [00:00, 44154.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "train_data = {}\n",
        "idx = 0\n",
        "\n",
        "predictions = []\n",
        "labels = []\n",
        "\n",
        "if setting==\"zero-shot\":\n",
        "    with open(train_file_zero_shot, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.reader(csvfile, delimiter=',')\n",
        "        for row in tqdm(reader):\n",
        "            \n",
        "            if len((row[4].strip() + row[5].strip() + row[6].strip()).split(\" \")) < 300:\n",
        "                text = row[4].strip()+ \" \" + row[5].strip()+ \" \" + row[6].strip()\n",
        "            elif len((row[4].strip() + row[5].strip()).split(\" \")) < 300:\n",
        "                text = row[4].strip()+ \" \" + row[5].strip()\n",
        "            else:\n",
        "                text = row[5].strip()\n",
        "                \n",
        "            e = row[2].strip()\n",
        "\n",
        "            train_data[idx] = {\n",
        "                                \"id\": row[0],\n",
        "                                \"lang\": row[1],\n",
        "                                \"expression\": e,\n",
        "                                \"text\": row[5].strip(),\n",
        "                                \"idiomatic\": True if row[7] == \"0\" else False\n",
        "                            }    \n",
        "            idx += 1\n",
        "\n",
        "\n",
        "if setting==\"one-shot\":\n",
        "    with open(train_file_one_shot, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.reader(csvfile, delimiter=',')\n",
        "        for row in tqdm(reader):\n",
        "            \n",
        "            if len((row[4].strip() + row[5].strip() + row[6].strip()).split(\" \")) < 300:\n",
        "                text = row[4].strip()+ \" \" + row[5].strip()+ \" \" + row[6].strip()\n",
        "            elif len((row[4].strip() + row[5].strip()).split(\" \")) < 300:\n",
        "                text = row[4].strip()+ \" \" + row[5].strip()\n",
        "            else:\n",
        "                text = row[5].strip()\n",
        "                \n",
        "            e = row[2].strip()\n",
        "                        \n",
        "            train_data[idx] = {\n",
        "                                \"id\": row[0],\n",
        "                                \"lang\": row[1],\n",
        "                                \"expression\": e,\n",
        "                                \"text\": row[5].strip(),\n",
        "                                \"idiomatic\": True if row[7] == \"0\" else False\n",
        "                            }    \n",
        "            idx += 1\n",
        "\n",
        "print(len(train_data)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2kWaYAsyaS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03287a1a-8411-492e-85d2-28de670c015e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "740\n"
          ]
        }
      ],
      "source": [
        "labels_dev = {}\n",
        "\n",
        "with open(dev_file_gold, newline='',encoding='utf-8') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    for row in reader:\n",
        "        labels_dev[row[0]] = True if row[3] == \"0\" else False\n",
        "\n",
        "dev_data = {}\n",
        "idx = 0\n",
        "\n",
        "with open(dev_file, newline='',encoding='utf-8') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    for row in reader:\n",
        "\n",
        "        if len((row[3].strip() + row[4].strip() + row[5].strip()).split(\" \")) < 300:\n",
        "            text = row[3].strip() + \" \" + row[4].strip()+ \" \" + row[5].strip()\n",
        "        elif len((row[3].strip() + row[4].strip()).split(\" \")) < 300:\n",
        "            text = row[3].strip()+ \" \" + row[4].strip()\n",
        "        else:\n",
        "            text = row[4].strip()\n",
        "        \n",
        "        e = row[2].strip()\n",
        "                \n",
        "        \n",
        "        dev_data[idx] = {\n",
        "                        \"id\": row[0],\n",
        "                        \"lang\": row[1],\n",
        "                        \"expression\": e,\n",
        "                        \"text\": row[4].strip(),\n",
        "                        \"idiomatic\": labels_dev[row[0]]\n",
        "                        }\n",
        "                \n",
        "        idx += 1\n",
        "        \n",
        "    \n",
        "print(len(dev_data)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRkJ9jo7Lq3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e00dd1-459a-4510-cd05-4bf6fc19ea93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2343\n"
          ]
        }
      ],
      "source": [
        "test_data = {}\n",
        "idx = 0\n",
        "\n",
        "with open(test_file, newline='', encoding='utf-8') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    for row in reader:\n",
        "\n",
        "        if len((row[3].strip() + row[4].strip() + row[5].strip()).split(\" \")) < 300:\n",
        "            text = row[3].strip()+ \" \" + row[4].strip()+ \" \" + row[5].strip()\n",
        "        elif len((row[3].strip() + row[4].strip()).split(\" \")) < 300:\n",
        "            text = row[3].strip()+ \" \" + row[4].strip()\n",
        "        else:\n",
        "            text = row[4].strip()\n",
        "        \n",
        "        e = row[2].strip()\n",
        "\n",
        "        test_data[idx] = {\n",
        "                            \"id\": row[0],\n",
        "                            \"lang\": row[1],\n",
        "                            \"expression\": e,\n",
        "                            \"text\": row[4].strip(),\n",
        "                            \"idiomatic\": True #it's just a FAKE label used to maintain the same structure of the dataset entries, \n",
        "                                              #it could be also False\n",
        "                        }\n",
        "                \n",
        "        idx += 1\n",
        "        \n",
        "    \n",
        "print(len(test_data)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kHKPydPLq3i"
      },
      "source": [
        "## Fix Random Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v_-Re97pfxI"
      },
      "outputs": [],
      "source": [
        "SEED = 2 #we set a seed for having replicability of results\n",
        " \n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkXJlVW2Lq3i"
      },
      "source": [
        "## Load BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkTPuDGIpi30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "53c6d21082724434b77ee14b1e388784",
            "5d13e2c9531e489e9c188ffb7fa02e59",
            "5fabd1c680c74647a8c61279875f3a3e",
            "af9f47c589ee4b269b6ce1ab6ff977c6",
            "d197826b48524d858a06d4379f7e6acf",
            "fa5f81f970874fcd88dca3449e60ba39",
            "5e96c956f13d48199d342af112a439b8",
            "468df0642d794a5fb5e24d19fd6f15bd",
            "d640e9135fc548b5aec812d32a3b8937",
            "b538f2203d3f4e6bbe2b2712a073512a",
            "115eb4ac4a194641938867fa6b0aa03c",
            "202989afe91e44c58fb8610bee9f4821",
            "f54f701b2da94861b92e950dce0e13c8",
            "3b59e1402b184c18b7fe5b67bfd9c0fe",
            "5aeb3103200449a79cf60ea9ef53b929",
            "bb9f935278724a77b235003ca5cf9d7a",
            "c7f2d6d04015404688c2c92d1cd2c3fb",
            "30a3091f5c524b5b98a32179f16f4732",
            "047b2272ef26473c912489ea50fe4da9",
            "4800655cfcde42d6b187e97bfd25695e",
            "cd320548bd2e407d9968f554ef8d7f82",
            "015ff7afe68640e1a0c817a6f0c3d650",
            "2080cad5a38f45759fff7b7bd258cdb1",
            "c5713ebd32e24f36b0ab36a5ae8d0574",
            "47b850b3703b4f64a87b43c129a3da75",
            "b3a5c390092d4d9bb813d7452476b184",
            "dcafa011af024405b096af4c08abe86f",
            "76221b18cd094d93a16ff454bc85dd0a",
            "eb18e21b0831483bb33dbd59ec88261c",
            "57fffc2aadc54f8b9b26adb73644c49d",
            "c56f2c1bd20b4a8a9afd5beb8f6fc863",
            "fedbc68f64a747d9ba3d535c47c7ee1d",
            "05d99147a6b045ca8200203a2f83d358",
            "f2e1f148811e40e3996ef33c2dd475ac",
            "c2d5c04c8c66465f84c939479125043e",
            "d4b3e450c73d48378d8f33c68da64953",
            "285c7e05baa742a6ae14f0ac563755f3",
            "fc4379a041dc4ec7a1e28e9226f0179e",
            "44172dfecca84e49abef56a07f0c5c25",
            "e939a46189264147bfdec04dfaaccd3c",
            "8838c3d2488544d6ad9d9902b0f5b855",
            "923432984beb493ab7aed979d99a69f7",
            "0f04ca5ed7ca4cb99625b52de575d402",
            "121c8d0428954d2e9b24a1304bbce4f3"
          ]
        },
        "outputId": "bb226baf-a1c5-4cb1-ffa2-a6c24015d554"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53c6d21082724434b77ee14b1e388784"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "202989afe91e44c58fb8610bee9f4821"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2080cad5a38f45759fff7b7bd258cdb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2e1f148811e40e3996ef33c2dd475ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model_name = 'bert-base-multilingual-cased'\n",
        " \n",
        "bert_config = BertConfig.from_pretrained(model_name, output_hidden_states=True)\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "bert_model = BertModel.from_pretrained(model_name, config=bert_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xepScwgoLq3j"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpd4vDOjprKv"
      },
      "outputs": [],
      "source": [
        "nlp_en = en_core_web_sm.load()\n",
        "nlp_pt = pt_core_news_sm.load()\n",
        "\n",
        "class IdiomDataset(Dataset):\n",
        "    def __init__(self, \n",
        "                 dataset, \n",
        "                 tokenizer,\n",
        "                 languages,\n",
        "                 device=\"cuda\",\n",
        "                ) -> None:\n",
        "        \n",
        "        self.encoded_data = []\n",
        "    \n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = tokenizer\n",
        "        self.languages = languages\n",
        "        self.device = device\n",
        "        self.__init_encoded_data()\n",
        "\n",
        " \n",
        "    def __init_encoded_data(self):\n",
        "                \n",
        "        for idx in tqdm(self.dataset):\n",
        "            id = self.dataset[idx][\"id\"]\n",
        "            lang = self.dataset[idx][\"lang\"]\n",
        "            e = self.dataset[idx][\"expression\"]\n",
        "            label = self.dataset[idx][\"idiomatic\"]\n",
        "            context_tmp = self.dataset[idx][\"text\"]\n",
        "\n",
        "            if lang == \"EN\":\n",
        "                doc = nlp_en(context_tmp)\n",
        "                ents = [X.text.lower() for X in doc.ents]\n",
        "            else:\n",
        "                doc = nlp_pt(context_tmp)\n",
        "                ents = [X.text.lower() for X in doc.ents]\n",
        "            \n",
        "    \n",
        "            if e in ents:\n",
        "                e = context_tmp\n",
        "                context = context_tmp\n",
        "            else:\n",
        "                if context_tmp.find(e) != -1:\n",
        "                    context = context_tmp[:context_tmp.lower().find(e)] + context_tmp[context_tmp.lower().find(e)+len(e):]\n",
        "\n",
        "                else:    \n",
        "                    e = context_tmp\n",
        "                    context = context_tmp                     \n",
        "                \n",
        "        \n",
        "            tokenized_e = torch.tensor(self.tokenize_mention(e, self.tokenizer, True))\n",
        "            tokenized_context = torch.tensor(self.tokenize_mention(context, self.tokenizer, True))\n",
        "\n",
        "            if e!=\"MWE\" and lang in self.languages:\n",
        "                self.encoded_data.append((idx,\n",
        "                                          e,\n",
        "                                          context,\n",
        "                                          tokenized_e,\n",
        "                                          tokenized_context,\n",
        "                                          torch.tensor([-1.0]) if label == True else torch.tensor([1.0]),\n",
        "                                          id, \n",
        "                                          lang))\n",
        "\n",
        "     \n",
        "    def tokenize_mention(self, sent, tokenizer, special_tokens):\n",
        "        encoded_sentence = tokenizer.encode(sent, add_special_tokens = special_tokens)\n",
        "        return encoded_sentence[:500]\n",
        "    \n",
        "    def tokenize_description(self, sent, tokenizer, window):\n",
        "        encoded_sentence = tokenizer.encode(sent, add_special_tokens = True)\n",
        "        return encoded_sentence\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoded_data)\n",
        " \n",
        "    def __getitem__(self, idx: int):\n",
        "        return self.encoded_data[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnindm3GLq3k"
      },
      "source": [
        "Create the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa72jvxrp8Na",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc6a1f7-c4b5-4800-8ee9-8d0a3b4bc995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4492/4492 [01:11<00:00, 62.89it/s]\n",
            "100%|██████████| 740/740 [00:08<00:00, 82.91it/s]\n",
            "100%|██████████| 2343/2343 [00:27<00:00, 84.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4491\n",
            "739\n",
            "2342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_dataset = IdiomDataset(train_data, bert_tokenizer, languages = [\"EN\", \"PT\", \"GL\"])\n",
        "dev_dataset = IdiomDataset(dev_data, bert_tokenizer, languages =[\"EN\", \"PT\", \"GL\"])\n",
        "test_dataset = IdiomDataset(test_data, bert_tokenizer, languages = [\"EN\",\"PT\", \"GL\"])\n",
        "\n",
        "print(len(train_dataset))\n",
        "print(len(dev_dataset))\n",
        "print(len(test_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKg_FjfULq3k"
      },
      "source": [
        "Create the dataloader:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfL32r72qBWh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6581a57-8525-4575-f484-b88512c160ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "562\n",
            "93\n",
            "293\n"
          ]
        }
      ],
      "source": [
        "def collate(elems: tuple) -> tuple:\n",
        "    ids, e, texts, expressions, contexts, labels, ids, langs = list(zip(*elems))\n",
        "    \n",
        "    pad_expressions = pad_sequence(expressions, batch_first=True, padding_value=0)\n",
        "    pad_contexts = pad_sequence(contexts, batch_first=True, padding_value=0)\n",
        "    pad_labels = pad_sequence(labels, batch_first=True, padding_value=0)\n",
        " \n",
        "    return ids, e, texts, pad_expressions, pad_contexts, pad_labels.cuda(), ids, langs\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate)\n",
        "dev_dataloader = DataLoader(dev_dataset, batch_size=8, shuffle=False, collate_fn=collate)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate)\n",
        "\n",
        "print(len(train_dataloader))\n",
        "print(len(dev_dataloader))\n",
        "print(len(test_dataloader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkNqGd1xLq3l"
      },
      "source": [
        "## Dual-Encoder Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfUxreHMpx4E"
      },
      "outputs": [],
      "source": [
        "class DualEncoder(nn.Module):\n",
        "    def __init__(self, hparams):\n",
        "        super(DualEncoder, self).__init__()\n",
        "        pprint(params)\n",
        " \n",
        "        self.hparams = hparams\n",
        " \n",
        "        self.expression_encoder = BertModel.from_pretrained(model_name, config=bert_config)\n",
        "        self.context_encoder = BertModel.from_pretrained(model_name, config=bert_config)\n",
        "\n",
        "        self.cosine_similarity = nn.CosineSimilarity(dim=-1, eps=1e-6)\n",
        "        \n",
        "        self.dropout = nn.Dropout(hparams.dropout)\n",
        "\n",
        "        self.tanh = nn.Tanh()\n",
        "            \n",
        "        for param in self.context_encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "  \n",
        "\n",
        "    def forward(self, expression, context, mask1, mask2):\n",
        "        \n",
        "        embedding_context = self.context_encoder.forward(context.cuda(), mask2.cuda())[0]\n",
        "        embedding_context = embedding_context[:,0,:].squeeze(1)\n",
        "\n",
        "        embedding_expression = self.expression_encoder.forward(expression.cuda(), mask1.cuda())[0]\n",
        "        embedding_expression = torch.sum(embedding_expression, 1)\n",
        "            \n",
        "        similarities = self.cosine_similarity(embedding_expression, embedding_context) \n",
        "                        \n",
        "        return similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqMKoAmZLq3l"
      },
      "outputs": [],
      "source": [
        "class HParams():\n",
        "    dropout = 0.25\n",
        "    \n",
        "params = HParams()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX0-n1yyLq3m"
      },
      "source": [
        "Instantiate the model: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeLvL3XELq3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c73243-a6e9-49ab-acb9-bd1c93912cf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.HParams object at 0x7f38f0922c50>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DualEncoder(\n",
              "  (expression_encoder): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (context_encoder): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (cosine_similarity): CosineSimilarity()\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              "  (tanh): Tanh()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "my_model = DualEncoder(params).cuda()\n",
        "my_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vblBvifLq3m"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0JfvAWUp6gc"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    def __init__(self,\n",
        "                model:nn.Module, \n",
        "                loss_function,\n",
        "                optimizer,\n",
        "                gradient_accumulation_steps):\n",
        "        \n",
        "        self.model = model\n",
        "        self.loss_function = loss_function\n",
        "        self.optimizer = optimizer\n",
        "        self.gradient_accumulation_steps = gradient_accumulation_steps\n",
        " \n",
        "    def padding_mask(self, batch):\n",
        "        padding = torch.ones_like(batch)\n",
        "        padding[batch == 0] = 0\n",
        "        padding = padding.type(torch.uint8)\n",
        "        return padding\n",
        " \n",
        "    def train(self,\n",
        "            train_dataset:Dataset, \n",
        "            valid_dataset:Dataset,\n",
        "            epochs:int=1,\n",
        "            patience:int=10,\n",
        "            modelname=setting):\n",
        "        \n",
        "        print(\"\\nTraining...\")\n",
        " \n",
        "        record_dev = 0.0\n",
        "        full_patience = patience\n",
        "        modelname = modelname\n",
        " \n",
        "        for epoch in range(epochs):\n",
        "             if patience>0:\n",
        "                print(\" Epoch {:03d}\".format(epoch + 1))\n",
        "\n",
        "                epoch_loss = 0.0\n",
        "                self.model.train()\n",
        "                \n",
        "                count_batches = 0\n",
        "                self.optimizer.zero_grad()\n",
        "                \n",
        "                for ids, e, text, expressions, contexts, labels, id, lang in tqdm(train_dataset):\n",
        "                    batch_loss = 0.0\n",
        "\n",
        "                    mask1 = self.padding_mask(expressions)\n",
        "                    mask2 = self.padding_mask(contexts)\n",
        "                    \n",
        "                    similarities = self.model(expressions, contexts, mask1, mask2)\n",
        "\n",
        "                    labels = labels.view(-1)\n",
        "                    batch_loss = self.loss_function(similarities, labels)\n",
        "                    epoch_loss += batch_loss\n",
        "\n",
        "                    batch_loss.backward()\n",
        "\n",
        "                    if count_batches % self.gradient_accumulation_steps == 0:\n",
        "                        self.optimizer.step()\n",
        "                        self.optimizer.zero_grad()\n",
        "\n",
        "\n",
        "                avg_epoch_loss = epoch_loss / len(train_dataset)\n",
        "                print('[E: {:2d}] train loss = {:0.4f}'.format(epoch+1, avg_epoch_loss))\n",
        "\n",
        "                valid_loss, f1 = self.evaluate(valid_dataset, epoch)\n",
        "\n",
        "                if f1>record_dev:\n",
        "                    record_dev = f1\n",
        "                    torch.save(self.model.state_dict(), \"/content/ner4id/checkpoints/\"+modelname+\".pt\")\n",
        "                    patience = full_patience\n",
        "                else:\n",
        "                    patience -= 1\n",
        "                   \n",
        "                print('\\t[E: {:2d}] valid loss = {:0.4f}, f1-score = {:0.4f}, patience: {:2d}'.format(epoch+1, valid_loss, f1, patience))\n",
        "\n",
        "\n",
        "        print(\"...Done!\")\n",
        "\n",
        "        return avg_epoch_loss\n",
        "\n",
        "    def evaluate(self, valid_dataset, epoch):\n",
        "\n",
        "        valid_loss = 0.0\n",
        "        all_predictions = list()\n",
        "        all_labels = list()\n",
        "        \n",
        "        predictions = {}\n",
        "         \n",
        "        self.model.eval()\n",
        "                    \n",
        "        for ids, e, text, expressions, contexts, labels, id, lang in tqdm(valid_dataset):\n",
        "            mask1 = self.padding_mask(expressions)\n",
        "            mask2 = self.padding_mask(contexts)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                similarities = self.model(expressions, contexts, mask1, mask2)\n",
        "\n",
        "            labels = labels.view(-1)\n",
        "            loss = self.loss_function(similarities, labels)\n",
        " \n",
        "            for i in range(len(similarities)):\n",
        "                if similarities[i]>0:\n",
        "                    all_predictions.append(1)\n",
        "                else:\n",
        "                    all_predictions.append(0)\n",
        "\n",
        "                all_labels.append(1 if labels[i].item()==1 else 0)\n",
        "            \n",
        "            valid_loss += loss\n",
        "            \n",
        "            for i in range(len(similarities)):\n",
        "                if similarities[i]>0:\n",
        "                    predictions[ids[i]] = 1\n",
        "\n",
        "                else:\n",
        "                    predictions[ids[i]] = 0\n",
        "\n",
        "        f1 = f1_score(all_labels, all_predictions, average= 'macro')\n",
        "        print(classification_report(all_labels, all_predictions, digits=4))\n",
        "        \n",
        "        return valid_loss / len(valid_dataset), f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E9dr6E3Lq3n"
      },
      "source": [
        "Instantiate the trainer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJOGLgoZqR9w"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(model = my_model,\n",
        "                    loss_function = nn.MSELoss(),\n",
        "                    optimizer = optim.Adam(my_model.parameters(), lr=0.00001),\n",
        "                    gradient_accumulation_steps=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUg_-1jrLq3o"
      },
      "source": [
        "Train the system:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0XLLlyoqU5_",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a27a3cac-aaeb-4efc-f9f6-08780c3486dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training...\n",
            " Epoch 001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562/562 [01:20<00:00,  6.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E:  1] train loss = 0.4616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:04<00:00, 20.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6286    0.9018    0.7408       336\n",
            "           1     0.8716    0.5558    0.6788       403\n",
            "\n",
            "    accuracy                         0.7131       739\n",
            "   macro avg     0.7501    0.7288    0.7098       739\n",
            "weighted avg     0.7611    0.7131    0.7070       739\n",
            "\n",
            "\t[E:  1] valid loss = 0.9194, f1-score = 0.7098, patience:  5\n",
            " Epoch 002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562/562 [01:21<00:00,  6.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E:  2] train loss = 0.2396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:04<00:00, 20.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5807    0.9315    0.7154       336\n",
            "           1     0.8850    0.4392    0.5871       403\n",
            "\n",
            "    accuracy                         0.6631       739\n",
            "   macro avg     0.7329    0.6854    0.6512       739\n",
            "weighted avg     0.7466    0.6631    0.6454       739\n",
            "\n",
            "\t[E:  2] valid loss = 1.0987, f1-score = 0.6512, patience:  4\n",
            " Epoch 003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562/562 [01:21<00:00,  6.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E:  3] train loss = 0.2111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:04<00:00, 20.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6464    0.8542    0.7359       336\n",
            "           1     0.8339    0.6104    0.7049       403\n",
            "\n",
            "    accuracy                         0.7212       739\n",
            "   macro avg     0.7401    0.7323    0.7204       739\n",
            "weighted avg     0.7486    0.7212    0.7190       739\n",
            "\n",
            "\t[E:  3] valid loss = 0.8874, f1-score = 0.7204, patience:  5\n",
            " Epoch 004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562/562 [01:21<00:00,  6.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E:  4] train loss = 0.1910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:04<00:00, 20.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6473    0.9286    0.7628       336\n",
            "           1     0.9066    0.5782    0.7061       403\n",
            "\n",
            "    accuracy                         0.7375       739\n",
            "   macro avg     0.7770    0.7534    0.7344       739\n",
            "weighted avg     0.7887    0.7375    0.7319       739\n",
            "\n",
            "\t[E:  4] valid loss = 0.8928, f1-score = 0.7344, patience:  5\n",
            " Epoch 005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562/562 [01:22<00:00,  6.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E:  5] train loss = 0.1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:04<00:00, 19.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6377    0.8958    0.7450       336\n",
            "           1     0.8689    0.5757    0.6925       403\n",
            "\n",
            "    accuracy                         0.7212       739\n",
            "   macro avg     0.7533    0.7358    0.7188       739\n",
            "weighted avg     0.7638    0.7212    0.7164       739\n",
            "\n",
            "\t[E:  5] valid loss = 0.9406, f1-score = 0.7188, patience:  4\n",
            " Epoch 006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562/562 [01:23<00:00,  6.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E:  6] train loss = 0.1760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:04<00:00, 19.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6343    0.8155    0.7135       336\n",
            "           1     0.7980    0.6079    0.6901       403\n",
            "\n",
            "    accuracy                         0.7023       739\n",
            "   macro avg     0.7162    0.7117    0.7018       739\n",
            "weighted avg     0.7236    0.7023    0.7008       739\n",
            "\n",
            "\t[E:  6] valid loss = 0.9659, f1-score = 0.7018, patience:  3\n",
            " Epoch 007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562/562 [01:22<00:00,  6.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E:  7] train loss = 0.1736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:04<00:00, 19.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6460    0.7768    0.7054       336\n",
            "           1     0.7761    0.6452    0.7046       403\n",
            "\n",
            "    accuracy                         0.7050       739\n",
            "   macro avg     0.7111    0.7110    0.7050       739\n",
            "weighted avg     0.7170    0.7050    0.7050       739\n",
            "\n",
            "\t[E:  7] valid loss = 0.9558, f1-score = 0.7050, patience:  2\n",
            " Epoch 008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562/562 [01:22<00:00,  6.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E:  8] train loss = 0.1626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:04<00:00, 19.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6333    0.8482    0.7252       336\n",
            "           1     0.8235    0.5906    0.6879       403\n",
            "\n",
            "    accuracy                         0.7077       739\n",
            "   macro avg     0.7284    0.7194    0.7065       739\n",
            "weighted avg     0.7371    0.7077    0.7048       739\n",
            "\n",
            "\t[E:  8] valid loss = 0.9754, f1-score = 0.7065, patience:  1\n",
            " Epoch 009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562/562 [01:22<00:00,  6.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E:  9] train loss = 0.1669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:04<00:00, 19.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6534    0.9256    0.7660       336\n",
            "           1     0.9049    0.5906    0.7147       403\n",
            "\n",
            "    accuracy                         0.7429       739\n",
            "   macro avg     0.7792    0.7581    0.7404       739\n",
            "weighted avg     0.7906    0.7429    0.7380       739\n",
            "\n",
            "\t[E:  9] valid loss = 0.8903, f1-score = 0.7404, patience:  5\n",
            " Epoch 010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562/562 [01:23<00:00,  6.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E: 10] train loss = 0.1669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:04<00:00, 19.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6484    0.8780    0.7459       336\n",
            "           1     0.8556    0.6030    0.7074       403\n",
            "\n",
            "    accuracy                         0.7280       739\n",
            "   macro avg     0.7520    0.7405    0.7267       739\n",
            "weighted avg     0.7614    0.7280    0.7249       739\n",
            "\n",
            "\t[E: 10] valid loss = 0.9322, f1-score = 0.7267, patience:  4\n",
            " Epoch 011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562/562 [01:22<00:00,  6.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E: 11] train loss = 0.1541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:04<00:00, 19.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6436    0.8869    0.7459       336\n",
            "           1     0.8623    0.5906    0.7010       403\n",
            "\n",
            "    accuracy                         0.7253       739\n",
            "   macro avg     0.7530    0.7387    0.7235       739\n",
            "weighted avg     0.7629    0.7253    0.7214       739\n",
            "\n",
            "\t[E: 11] valid loss = 0.9439, f1-score = 0.7235, patience:  3\n",
            " Epoch 012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562/562 [01:22<00:00,  6.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E: 12] train loss = 0.1584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:04<00:00, 19.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6432    0.8690    0.7392       336\n",
            "           1     0.8456    0.5980    0.7006       403\n",
            "\n",
            "    accuracy                         0.7212       739\n",
            "   macro avg     0.7444    0.7335    0.7199       739\n",
            "weighted avg     0.7536    0.7212    0.7182       739\n",
            "\n",
            "\t[E: 12] valid loss = 0.9532, f1-score = 0.7199, patience:  2\n",
            " Epoch 013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562/562 [01:22<00:00,  6.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E: 13] train loss = 0.1523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:04<00:00, 19.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6427    0.7976    0.7118       336\n",
            "           1     0.7888    0.6303    0.7007       403\n",
            "\n",
            "    accuracy                         0.7064       739\n",
            "   macro avg     0.7158    0.7139    0.7063       739\n",
            "weighted avg     0.7224    0.7064    0.7057       739\n",
            "\n",
            "\t[E: 13] valid loss = 0.9883, f1-score = 0.7063, patience:  1\n",
            " Epoch 014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562/562 [01:22<00:00,  6.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E: 14] train loss = 0.1604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:04<00:00, 18.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6374    0.8423    0.7256       336\n",
            "           1     0.8203    0.6005    0.6934       403\n",
            "\n",
            "    accuracy                         0.7104       739\n",
            "   macro avg     0.7289    0.7214    0.7095       739\n",
            "weighted avg     0.7372    0.7104    0.7081       739\n",
            "\n",
            "\t[E: 14] valid loss = 0.9648, f1-score = 0.7095, patience:  0\n",
            "...Done!\n"
          ]
        }
      ],
      "source": [
        "if mode == \"train\":\n",
        "    trainer.train(train_dataloader, dev_dataloader, epochs = 1000, patience = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjmcwPBqLq3p"
      },
      "source": [
        "## Predict the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnZS3NeULq3p"
      },
      "source": [
        "Load the best model checkpoint:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W27iGKuNLq3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cd056a5-2ff6-4082-a6bb-3689ff42da1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "my_model.load_state_dict(torch.load(f\"/content/ner4id/checkpoints/{setting}.pt\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdXzd-NbLq3p"
      },
      "source": [
        "and then use the model to predict the test set:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "folder_name = \"predictions\"\n",
        "par_dir = \"/content/ner4id\"\n",
        "path = os.path.join(par_dir, folder_name)\n",
        "os.makedirs(path)"
      ],
      "metadata": {
        "id": "c3ViZ3OUqdXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjt7AH1FvXyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7197ffcd-cea6-4f33-c9de-3c4ee8b6d8db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 293/293 [00:14<00:00, 19.87it/s]\n"
          ]
        }
      ],
      "source": [
        "def padding_mask(batch):\n",
        "        padding = torch.ones_like(batch)\n",
        "        padding[batch == 0] = 0\n",
        "        padding = padding.type(torch.uint8)\n",
        "        return padding\n",
        "\n",
        "def predict(model, test_dataset):\n",
        "\n",
        "    predictions = {}\n",
        "        \n",
        "    model.eval()\n",
        "                \n",
        "    for ids, e, text, expressions, contexts, labels, id, lang in tqdm(test_dataset):\n",
        "        mask1 = padding_mask(expressions)\n",
        "        mask2 = padding_mask(contexts)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            similarities = model(expressions, contexts, mask1, mask2)\n",
        "\n",
        "        labels = labels.view(-1)\n",
        "\n",
        "        for i in range(len(similarities)):\n",
        "            if similarities[i]>0:\n",
        "                predictions[ids[i]] = 1\n",
        "\n",
        "            else:\n",
        "                predictions[ids[i]] = 0\n",
        "\n",
        "\n",
        "    predictions[\"ID\"] = \"Label\"\n",
        "\n",
        "    if setting == \"zero-shot\":\n",
        "        with open(\"/content/ner4id/data/test_submission_format.csv\") as csvfile:\n",
        "            with open(\"/content/ner4id/predictions/task2_subtaska.csv\", \"w\") as out:\n",
        "                reader = csv.reader(csvfile, delimiter=',')\n",
        "                for row in reader:\n",
        "                    if row[2] == \"zero_shot\" or row[0] == \"ID\":\n",
        "                        out.write(row[0] + \",\" + row[1] + \",\" + row[2] + \",\" + str(predictions[row[0]]) + \"\\n\")\n",
        "                    else:\n",
        "                        out.write(row[0] + \",\" + row[1] + \",\" + row[2] + \",\" + \"\" + \"\\n\")\n",
        "    else:\n",
        "        with open(\"/content/ner4id/data/test_submission_format.csv\") as csvfile:\n",
        "            with open(\"/content/ner4id/predictions/task2_subtaska.csv\", \"w\") as out:\n",
        "                reader = csv.reader(csvfile, delimiter=',')\n",
        "                for row in reader:\n",
        "                    if row[2] == \"one_shot\" or row[0] == \"ID\":\n",
        "                        out.write(row[0] + \",\" + row[1] + \",\" + row[2] + \",\" + str(predictions[row[0]]) + \"\\n\")\n",
        "                    else:\n",
        "                        out.write(row[0] + \",\" + row[1] + \",\" + row[2] + \",\" + \"\" + \"\\n\")    \n",
        "\n",
        "\n",
        "predict(my_model, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIr7Ph4YLq3r"
      },
      "source": [
        "The output file (saved in the /predictions folder) contains predictions in the standard format specified by the competition rules. You can now upload the output file on CodaLab and see the scores obtained by the system on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Robustness testing"
      ],
      "metadata": {
        "id": "aRM17i1b0I3S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Experiment **1**"
      ],
      "metadata": {
        "id": "c32WU9wz4Sr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "robust_dataset = \"/content/ner4id/data/robust_2.csv\"\n",
        "robust_data = {}\n",
        "idx = 0\n",
        "\n",
        "with open(robust_dataset, newline='', encoding='utf-8') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    for row in reader:\n",
        "\n",
        "        if len((row[3].strip() + row[4].strip() + row[5].strip()).split(\" \")) < 300:\n",
        "            text = row[3].strip()+ \" \" + row[4].strip()+ \" \" + row[5].strip()\n",
        "        elif len((row[3].strip() + row[4].strip()).split(\" \")) < 300:\n",
        "            text = row[3].strip()+ \" \" + row[4].strip()\n",
        "        else:\n",
        "            text = row[4].strip()\n",
        "        \n",
        "        e = row[2].strip()\n",
        "\n",
        "        robust_data[idx] = {\n",
        "                            \"id\": row[0],\n",
        "                            \"lang\": row[1],\n",
        "                            \"expression\": e,\n",
        "                            \"text\": row[4].strip(),\n",
        "                            \"idiomatic\": True #it's just a FAKE label used to maintain the same structure of the dataset entries, \n",
        "                                              #it could be also False\n",
        "                        }\n",
        "                \n",
        "        idx += 1\n",
        "        \n",
        "    \n",
        "print(len(robust_data)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvIrUWnl4ath",
        "outputId": "d4ab4141-7936-473c-bca7-a0e6b85c07bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "robust_dataset = IdiomDataset(robust_data, bert_tokenizer, languages = [\"EN\",\"PT\", \"GL\"])\n",
        "robust_dataloader = DataLoader(robust_dataset, shuffle=False, collate_fn=collate)\n",
        "print(len(robust_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc6Lsmvf4ad5",
        "outputId": "f27c7f40-79bd-4101-ebc1-1df32f7ae808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 210/210 [00:03<00:00, 53.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_robust(model, test_dataset):\n",
        "\n",
        "    predictions = {}\n",
        "        \n",
        "    model.eval()\n",
        "                \n",
        "    for ids, e, text, expressions, contexts, labels, id, lang in tqdm(test_dataset):\n",
        "        mask1 = padding_mask(expressions)\n",
        "        mask2 = padding_mask(contexts)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            similarities = model(expressions, contexts, mask1, mask2)\n",
        "\n",
        "        labels = labels.view(-1)\n",
        "\n",
        "        for i in range(len(similarities)):\n",
        "            if similarities[i]>0:\n",
        "                predictions[ids[i]] = 1\n",
        "\n",
        "            else:\n",
        "                predictions[ids[i]] = 0\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "mQWLbQiM4aXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = predict_robust(my_model, robust_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrcA0OlO4aO5",
        "outputId": "9d79e36a-47f8-40c9-b581-7f7e3171dd72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 209/209 [00:05<00:00, 37.63it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_pred = predictions.values()\n",
        "list_pred = list(list_pred)"
      ],
      "metadata": {
        "id": "AnP_7Su84aCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "actual = pd.read_csv(\"/content/ner4id/data/robust_2keys - Sheet1.csv\")\n",
        "actual_values = actual['Label'].tolist()\n",
        "len(actual_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAqTCxUe4Z64",
        "outputId": "9b277af9-0208-48da-eba7-03e8dd16fd1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "209"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(actual_values, list_pred, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxxVit5L4Z01",
        "outputId": "46eb6d1a-e4a4-433b-df03-0ff596868f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6446    0.9068    0.7535       118\n",
            "           1     0.7442    0.3516    0.4776        91\n",
            "\n",
            "    accuracy                         0.6651       209\n",
            "   macro avg     0.6944    0.6292    0.6156       209\n",
            "weighted avg     0.6879    0.6651    0.6334       209\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 2"
      ],
      "metadata": {
        "id": "N4qoANb0cO3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "robust_dataset = \"/content/ner4id/data/robust_3.csv\"\n",
        "robust_data = {}\n",
        "idx = 0\n",
        "\n",
        "with open(robust_dataset, newline='', encoding='utf-8') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    for row in reader:\n",
        "\n",
        "        if len((row[3].strip() + row[4].strip() + row[5].strip()).split(\" \")) < 300:\n",
        "            text = row[3].strip()+ \" \" + row[4].strip()+ \" \" + row[5].strip()\n",
        "        elif len((row[3].strip() + row[4].strip()).split(\" \")) < 300:\n",
        "            text = row[3].strip()+ \" \" + row[4].strip()\n",
        "        else:\n",
        "            text = row[4].strip()\n",
        "        \n",
        "        e = row[2].strip()\n",
        "\n",
        "        robust_data[idx] = {\n",
        "                            \"id\": row[0],\n",
        "                            \"lang\": row[1],\n",
        "                            \"expression\": e,\n",
        "                            \"text\": row[4].strip(),\n",
        "                            \"idiomatic\": True #it's just a FAKE label used to maintain the same structure of the dataset entries, \n",
        "                                              #it could be also False\n",
        "                        }\n",
        "                \n",
        "        idx += 1\n",
        "        \n",
        "    \n",
        "print(len(robust_data)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWQNyummcOSb",
        "outputId": "6ef82bfa-1e09-43ad-e07e-60bc36b1116f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "robust_dataset = IdiomDataset(robust_data, bert_tokenizer, languages = [\"EN\",\"PT\", \"GL\"])\n",
        "robust_dataloader = DataLoader(robust_dataset, shuffle=False, collate_fn=collate)\n",
        "print(len(robust_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rh6HRDnBca1a",
        "outputId": "f02d7644-6fc9-47b6-e620-ecea93dd2ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 210/210 [00:03<00:00, 59.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_robust(model, test_dataset):\n",
        "\n",
        "    predictions = {}\n",
        "        \n",
        "    model.eval()\n",
        "                \n",
        "    for ids, e, text, expressions, contexts, labels, id, lang in tqdm(test_dataset):\n",
        "        mask1 = padding_mask(expressions)\n",
        "        mask2 = padding_mask(contexts)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            similarities = model(expressions, contexts, mask1, mask2)\n",
        "\n",
        "        labels = labels.view(-1)\n",
        "\n",
        "        for i in range(len(similarities)):\n",
        "            if similarities[i]>0:\n",
        "                predictions[ids[i]] = 1\n",
        "\n",
        "            else:\n",
        "                predictions[ids[i]] = 0\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "XP6yiXOzc1Eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = predict_robust(my_model, robust_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArGjUhcIc0lY",
        "outputId": "3325cec3-2703-490a-8900-80164cbc9477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 209/209 [00:07<00:00, 27.74it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_pred = predictions.values()\n",
        "list_pred = list(list_pred)"
      ],
      "metadata": {
        "id": "ti1i3ExMc0DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "actual = pd.read_csv(\"/content/ner4id/data/robust_2keys - Sheet1.csv\")\n",
        "actual_values = actual['Label'].tolist()\n",
        "len(actual_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB5oHydOdOJ1",
        "outputId": "7917aebb-ed29-473d-9473-41b09be09cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "209"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(actual_values, list_pred, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "827BikTjdNnE",
        "outputId": "c22f64cf-8d17-4af7-d948-0cb1df7e21a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6446    0.9068    0.7535       118\n",
            "           1     0.7442    0.3516    0.4776        91\n",
            "\n",
            "    accuracy                         0.6651       209\n",
            "   macro avg     0.6944    0.6292    0.6156       209\n",
            "weighted avg     0.6879    0.6651    0.6334       209\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment 3(All Perturbations)"
      ],
      "metadata": {
        "id": "3H38VV5H4djL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "robust_dataset = \"/content/ner4id/data/robust_5.csv\"\n",
        "robust_data = {}\n",
        "idx = 0\n",
        "\n",
        "with open(robust_dataset, newline='', encoding='utf-8') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    for row in reader:\n",
        "\n",
        "        if len((row[3].strip() + row[4].strip() + row[5].strip()).split(\" \")) < 300:\n",
        "            text = row[3].strip()+ \" \" + row[4].strip()+ \" \" + row[5].strip()\n",
        "        elif len((row[3].strip() + row[4].strip()).split(\" \")) < 300:\n",
        "            text = row[3].strip()+ \" \" + row[4].strip()\n",
        "        else:\n",
        "            text = row[4].strip()\n",
        "        \n",
        "        e = row[2].strip()\n",
        "\n",
        "        robust_data[idx] = {\n",
        "                            \"id\": row[0],\n",
        "                            \"lang\": row[1],\n",
        "                            \"expression\": e,\n",
        "                            \"text\": row[4].strip(),\n",
        "                            \"idiomatic\": True #it's just a FAKE label used to maintain the same structure of the dataset entries, \n",
        "                                              #it could be also False\n",
        "                        }\n",
        "                \n",
        "        idx += 1\n",
        "        \n",
        "    \n",
        "print(len(robust_data)) \n"
      ],
      "metadata": {
        "id": "iP2zVck6z_W2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec35ff6-2114-43fc-8937-6aede63442c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "robust_dataset = IdiomDataset(robust_data, bert_tokenizer, languages = [\"EN\",\"PT\", \"GL\"])\n",
        "robust_dataloader = DataLoader(robust_dataset, shuffle=False, collate_fn=collate)\n",
        "print(len(robust_dataloader))"
      ],
      "metadata": {
        "id": "8IhrFsZjKhZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2470b32-2cff-40fc-9e0d-f9fc00c7db90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 210/210 [00:05<00:00, 36.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_robust(model, test_dataset):\n",
        "\n",
        "    predictions = {}\n",
        "        \n",
        "    model.eval()\n",
        "                \n",
        "    for ids, e, text, expressions, contexts, labels, id, lang in tqdm(test_dataset):\n",
        "        mask1 = padding_mask(expressions)\n",
        "        mask2 = padding_mask(contexts)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            similarities = model(expressions, contexts, mask1, mask2)\n",
        "\n",
        "        labels = labels.view(-1)\n",
        "\n",
        "        for i in range(len(similarities)):\n",
        "            if similarities[i]>0:\n",
        "                predictions[ids[i]] = 1\n",
        "\n",
        "            else:\n",
        "                predictions[ids[i]] = 0\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "sPDDdNB6O0gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = predict_robust(my_model, robust_dataloader)"
      ],
      "metadata": {
        "id": "NNXQzoVxMuIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34115e28-444b-4519-b38b-d9006b1e00d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 209/209 [00:05<00:00, 36.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_pred = predictions.values()\n",
        "list_pred = list(list_pred)"
      ],
      "metadata": {
        "id": "BkVPtTesOkfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "actual = pd.read_csv(\"/content/ner4id/data/robust_2keys - Sheet1.csv\")\n",
        "actual_values = actual['Label'].tolist()\n",
        "len(actual_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifLVNDF40eM1",
        "outputId": "2dff9080-e3bd-48d3-8ec2-d52a68ba98fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "209"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(actual_values, list_pred, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIYwOAPp1g2Y",
        "outputId": "f8676aa7-23a5-4cb1-e1df-4194850fbe2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6446    0.9068    0.7535       118\n",
            "           1     0.7442    0.3516    0.4776        91\n",
            "\n",
            "    accuracy                         0.6651       209\n",
            "   macro avg     0.6944    0.6292    0.6156       209\n",
            "weighted avg     0.6879    0.6651    0.6334       209\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment on real world data."
      ],
      "metadata": {
        "id": "N1Lbi4QmiiCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "robust_dataset = \"/content/ner4id/data/robust_final.csv\"\n",
        "robust_data = {}\n",
        "idx = 0\n",
        "\n",
        "with open(robust_dataset, newline='', encoding='utf-8') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    for row in reader:\n",
        "\n",
        "        if len((row[3].strip() + row[4].strip() + row[5].strip()).split(\" \")) < 300:\n",
        "            text = row[3].strip()+ \" \" + row[4].strip()+ \" \" + row[5].strip()\n",
        "        elif len((row[3].strip() + row[4].strip()).split(\" \")) < 300:\n",
        "            text = row[3].strip()+ \" \" + row[4].strip()\n",
        "        else:\n",
        "            text = row[4].strip()\n",
        "        \n",
        "        e = row[2].strip()\n",
        "\n",
        "        robust_data[idx] = {\n",
        "                            \"id\": row[0],\n",
        "                            \"lang\": row[1],\n",
        "                            \"expression\": e,\n",
        "                            \"text\": row[4].strip(),\n",
        "                            \"idiomatic\": True #it's just a FAKE label used to maintain the same structure of the dataset entries, \n",
        "                                              #it could be also False\n",
        "                        }\n",
        "                \n",
        "        idx += 1\n",
        "        \n",
        "    \n",
        "print(len(robust_data)) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZzhPCFx2kij",
        "outputId": "749134cb-3314-4baa-94d7-13a0c61450d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "robust_dataset = IdiomDataset(robust_data, bert_tokenizer, languages = [\"EN\",\"PT\", \"GL\"])\n",
        "robust_dataloader = DataLoader(robust_dataset, shuffle=False, collate_fn=collate)\n",
        "print(len(robust_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXP_8M0m34AN",
        "outputId": "8f1161ee-5a15-4a70-f41b-c7a5a5c8d429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:00<00:00, 30.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_robust(model, test_dataset):\n",
        "\n",
        "    predictions = {}\n",
        "        \n",
        "    model.eval()\n",
        "                \n",
        "    for ids, e, text, expressions, contexts, labels, id, lang in tqdm(test_dataset):\n",
        "        mask1 = padding_mask(expressions)\n",
        "        mask2 = padding_mask(contexts)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            similarities = model(expressions, contexts, mask1, mask2)\n",
        "\n",
        "        labels = labels.view(-1)\n",
        "\n",
        "        for i in range(len(similarities)):\n",
        "            if similarities[i]>0:\n",
        "                predictions[ids[i]] = 1\n",
        "\n",
        "            else:\n",
        "                predictions[ids[i]] = 0\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "bSCWlaMZkQE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = predict_robust(my_model, robust_dataloader)"
      ],
      "metadata": {
        "id": "6snnaNq8kbXc",
        "outputId": "c3e36d15-3004-4a7e-9673-e12c072716ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 27.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_pred = predictions.values()\n",
        "list_pred = list(list_pred)"
      ],
      "metadata": {
        "id": "0v0LEL0Mkj-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "actual = pd.read_csv(\"/content/ner4id/data/robust_finalkeys - Sheet1.csv\")\n",
        "actual_values = actual['Label'].tolist()\n",
        "len(actual_values)"
      ],
      "metadata": {
        "id": "MJXKghKSkt93",
        "outputId": "df0e7f38-3543-4e87-8404-182dfd25638a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(actual_values, list_pred, digits=4))"
      ],
      "metadata": {
        "id": "e5Qqbxl7lC59",
        "outputId": "ff4e7b5b-6eb9-4818-c398-6f2e35669027",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7857    0.9167    0.8462        12\n",
            "           1     0.8333    0.6250    0.7143         8\n",
            "\n",
            "    accuracy                         0.8000        20\n",
            "   macro avg     0.8095    0.7708    0.7802        20\n",
            "weighted avg     0.8048    0.8000    0.7934        20\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o0nXlLxglTNM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "interpreter": {
      "hash": "6f64be793538f7fe230f350828c9baf03d97c4df0981f52e8388f53f367f4a42"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('torch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "53c6d21082724434b77ee14b1e388784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d13e2c9531e489e9c188ffb7fa02e59",
              "IPY_MODEL_5fabd1c680c74647a8c61279875f3a3e",
              "IPY_MODEL_af9f47c589ee4b269b6ce1ab6ff977c6"
            ],
            "layout": "IPY_MODEL_d197826b48524d858a06d4379f7e6acf"
          }
        },
        "5d13e2c9531e489e9c188ffb7fa02e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa5f81f970874fcd88dca3449e60ba39",
            "placeholder": "​",
            "style": "IPY_MODEL_5e96c956f13d48199d342af112a439b8",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "5fabd1c680c74647a8c61279875f3a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_468df0642d794a5fb5e24d19fd6f15bd",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d640e9135fc548b5aec812d32a3b8937",
            "value": 625
          }
        },
        "af9f47c589ee4b269b6ce1ab6ff977c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b538f2203d3f4e6bbe2b2712a073512a",
            "placeholder": "​",
            "style": "IPY_MODEL_115eb4ac4a194641938867fa6b0aa03c",
            "value": " 625/625 [00:00&lt;00:00, 16.2kB/s]"
          }
        },
        "d197826b48524d858a06d4379f7e6acf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa5f81f970874fcd88dca3449e60ba39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e96c956f13d48199d342af112a439b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "468df0642d794a5fb5e24d19fd6f15bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d640e9135fc548b5aec812d32a3b8937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b538f2203d3f4e6bbe2b2712a073512a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "115eb4ac4a194641938867fa6b0aa03c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "202989afe91e44c58fb8610bee9f4821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f54f701b2da94861b92e950dce0e13c8",
              "IPY_MODEL_3b59e1402b184c18b7fe5b67bfd9c0fe",
              "IPY_MODEL_5aeb3103200449a79cf60ea9ef53b929"
            ],
            "layout": "IPY_MODEL_bb9f935278724a77b235003ca5cf9d7a"
          }
        },
        "f54f701b2da94861b92e950dce0e13c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7f2d6d04015404688c2c92d1cd2c3fb",
            "placeholder": "​",
            "style": "IPY_MODEL_30a3091f5c524b5b98a32179f16f4732",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "3b59e1402b184c18b7fe5b67bfd9c0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_047b2272ef26473c912489ea50fe4da9",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4800655cfcde42d6b187e97bfd25695e",
            "value": 995526
          }
        },
        "5aeb3103200449a79cf60ea9ef53b929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd320548bd2e407d9968f554ef8d7f82",
            "placeholder": "​",
            "style": "IPY_MODEL_015ff7afe68640e1a0c817a6f0c3d650",
            "value": " 996k/996k [00:03&lt;00:00, 327kB/s]"
          }
        },
        "bb9f935278724a77b235003ca5cf9d7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7f2d6d04015404688c2c92d1cd2c3fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30a3091f5c524b5b98a32179f16f4732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "047b2272ef26473c912489ea50fe4da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4800655cfcde42d6b187e97bfd25695e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd320548bd2e407d9968f554ef8d7f82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "015ff7afe68640e1a0c817a6f0c3d650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2080cad5a38f45759fff7b7bd258cdb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5713ebd32e24f36b0ab36a5ae8d0574",
              "IPY_MODEL_47b850b3703b4f64a87b43c129a3da75",
              "IPY_MODEL_b3a5c390092d4d9bb813d7452476b184"
            ],
            "layout": "IPY_MODEL_dcafa011af024405b096af4c08abe86f"
          }
        },
        "c5713ebd32e24f36b0ab36a5ae8d0574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76221b18cd094d93a16ff454bc85dd0a",
            "placeholder": "​",
            "style": "IPY_MODEL_eb18e21b0831483bb33dbd59ec88261c",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "47b850b3703b4f64a87b43c129a3da75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57fffc2aadc54f8b9b26adb73644c49d",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c56f2c1bd20b4a8a9afd5beb8f6fc863",
            "value": 29
          }
        },
        "b3a5c390092d4d9bb813d7452476b184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fedbc68f64a747d9ba3d535c47c7ee1d",
            "placeholder": "​",
            "style": "IPY_MODEL_05d99147a6b045ca8200203a2f83d358",
            "value": " 29.0/29.0 [00:00&lt;00:00, 2.27kB/s]"
          }
        },
        "dcafa011af024405b096af4c08abe86f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76221b18cd094d93a16ff454bc85dd0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb18e21b0831483bb33dbd59ec88261c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57fffc2aadc54f8b9b26adb73644c49d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c56f2c1bd20b4a8a9afd5beb8f6fc863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fedbc68f64a747d9ba3d535c47c7ee1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05d99147a6b045ca8200203a2f83d358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2e1f148811e40e3996ef33c2dd475ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2d5c04c8c66465f84c939479125043e",
              "IPY_MODEL_d4b3e450c73d48378d8f33c68da64953",
              "IPY_MODEL_285c7e05baa742a6ae14f0ac563755f3"
            ],
            "layout": "IPY_MODEL_fc4379a041dc4ec7a1e28e9226f0179e"
          }
        },
        "c2d5c04c8c66465f84c939479125043e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44172dfecca84e49abef56a07f0c5c25",
            "placeholder": "​",
            "style": "IPY_MODEL_e939a46189264147bfdec04dfaaccd3c",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "d4b3e450c73d48378d8f33c68da64953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8838c3d2488544d6ad9d9902b0f5b855",
            "max": 714314041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_923432984beb493ab7aed979d99a69f7",
            "value": 714314041
          }
        },
        "285c7e05baa742a6ae14f0ac563755f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f04ca5ed7ca4cb99625b52de575d402",
            "placeholder": "​",
            "style": "IPY_MODEL_121c8d0428954d2e9b24a1304bbce4f3",
            "value": " 714M/714M [00:04&lt;00:00, 134MB/s]"
          }
        },
        "fc4379a041dc4ec7a1e28e9226f0179e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44172dfecca84e49abef56a07f0c5c25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e939a46189264147bfdec04dfaaccd3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8838c3d2488544d6ad9d9902b0f5b855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "923432984beb493ab7aed979d99a69f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f04ca5ed7ca4cb99625b52de575d402": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "121c8d0428954d2e9b24a1304bbce4f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}